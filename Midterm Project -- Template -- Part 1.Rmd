---
title: "Data Science Consulting:  Midterm Team Project -- Part 1"
author: ""
date: ""
output: html_document
---

```{r setup, include=FALSE}
set.seed(72)
knitr::opts_chunk$set(echo = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55))
```

```{r libraries, echo = FALSE}
library(data.table)
library(DT)
library(randomForest)
library(caret)
library(rpart)
```

```{r source_files}

```

```{r functions}
#sample generation function
sample_split = function(data,size,n){
  sample_data <- data[sample(1:nrow(data), size*3), ]
  sample_split <-split(sample_data, 
                       rep(1:3, length.out = nrow(sample_data), 
                           each = ceiling(nrow(sample_data)/3)))
  return(sample_split[[n]])
}

#iteration function
model_iteration <- function(model, rf_ntree){
  if(model == "Multi Log Reg"){
    for(i in samples){
      sample = get(i)
      multi_log_reg(sample)
    }
  } else if(model == "K Neighbors"){
    for(i in samples){
      sample = get(i)
      k_neighbors(sample)
    }
  } else if(model == "Random Forest"){
    for(i in samples){
      sample = get(i)
      random_forest(sample, rf_ntree)
    }
  } else if(model == "Classification Tree"){
    for(i in samples){
      sample = get(i)
      classification_tree(sample)
    }
  } else if(model == "GLM"){
    for(i in samples){
      sample = get(i)
      glm(sample)
    }
  } else if(model == "SVM"){
    for(i in samples){
      sample = get(i)
      support_vector_machine(sample)
    }
  } else if(model == "XGBoost"){
    for(i in samples){
      sample = get(i)
      generalized_boost_regression(sample)
    }
  } else if(model == "Neural Network"){
    for(i in samples){
      sample = get(i)
      nn(sample)
    }
  } 
}
```

```{r constants}
n.values <- c(500, 1000, 2000)
iterations <- 3
samples <- c("dat_500_1", "dat_500_2", "dat_500_3", 
             "dat_1000_1", "dat_1000_2", "dat_1000_3",
             "dat_2000_1", "dat_2000_2", "dat_2000_3")
```

```{r load_data}
train <- read.csv("MNIST-fashion training set-49.csv")
test <- read.csv("MNIST-fashion testing set-49.csv")
```

```{r clean_data}
train$label = factor(train$label)
test$label = factor(test$label)
```

```{r generate_samples}
dat_500_1 <- sample_split(train, 500, 1)
dat_500_2 <- sample_split(train, 500, 2)
dat_500_3 <- sample_split(train, 500, 3)
dat_1000_1 <- sample_split(train, 1000, 1)
dat_1000_2 <- sample_split(train, 1000, 2)
dat_1000_3 <- sample_split(train, 1000, 3)
dat_2000_1 <- sample_split(train, 2000, 1)
dat_2000_2 <- sample_split(train, 2000, 2)
dat_2000_3 <- sample_split(train, 2000, 3)
```

## Introduction {.tabset}


### Model 1



```{r code_model1_development, eval = TRUE}
#random forest
random_forest <- function(sample, ntree){
  set.seed(72)
  
  #model tuning
  trControl = trainControl(method = 'cv', number = 49)
  tuneGrid = expand.grid(mtry = 2:49)
  cvModel = train(label ~ ., data = sample, method = 'rf', ntree = ntree,
                trControl = trControl, tuneGrid = tuneGrid)
  cvForest = randomForest(label ~ ., data = sample, ntree = ntree, mytry = cvModel$bestTune$mtry)
  
  #predicting test set
  cvForest_pred = predict(cvForest, newdata = test)
  return(model)
  #return(print(confusionMatrix(cvForest_pred, test$label)$overall['Accuracy']))
}
```

```{r load_model1}
model_iteration(model = "Random Forest", rf_ntree = 10)
```

### Model 2


```{r code_model2_development, eval = TRUE}
#classification tree
classification_tree <- function(sample){
  tree <- rpart(label ~ ., data = sample, method = 'class')
  pred <- predict(tree, newdata = test, type = "class")
  ct <- table(test$label, predictions = pred)
  accuracy <- sum(diag(ct)) / sum(ct)
  return(tree)
  #return(print(accuracy))
}
```

```{r load_model2}
model_iteration(model = "Classification Tree")
```

### Model 3


```{r code_model3_development, eval = TRUE}

```

```{r load_model3}

```

### Model 4


```{r code_model4_development, eval = TRUE}

```

```{r load_model4}

```

### Model 5


```{r code_model5_development, eval = TRUE}

```

```{r load_model5}

```

### Model 6


```{r code_model6_development, eval = TRUE}

```

```{r load_model6}

```

### Model 7


```{r code_model7_development, eval = TRUE}

```

```{r load_model7}

```

### Model 8


```{r code_model8_development, eval = TRUE}

```

```{r load_model8}

```

### Model 9


```{r code_model9_development, eval = TRUE}

```

```{r load_model9}

```

### Model 10


```{r code_model10_development, eval = TRUE}

```

```{r load_model10}

```

## Scoreboard

```{r scoreboard}

```

## Discussion


## Model Development Responsibilities

For the 10 models, please list the names of the developers along with percentages for how the responsibilities were divided.

1.  
2. 
3. 
4.
5.
6.
7.
8.
9.
10.

## References


